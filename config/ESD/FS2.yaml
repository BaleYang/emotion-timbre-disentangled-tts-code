# 用multihead attention算score，得到emotional embedding

model_name: "FS2"
version_name: 'FS2'

transformer:
  encoder_layer: 6
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 6
  decoder_head: 2
  decoder_hidden: 256
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.2
  decoder_dropout: 0.2

variance_predictor:
  filter_size: 256
  kernel_size: 3
  dropout: 0.5

variance_embedding:
  pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
  energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
  n_bins: 256

emotion_predictor:
  style_encoder:
    hidden_dim: 256

  mist:
    num_encoder_blocks: 2

  reference_encoder:
    conv_filters: [32, 32, 64, 64, 128, 128]
    gru_hidden: 256

    conv_filters1: [32, 32, 64, 64, 128, 128]
    conv_filters2: []


  phoneme_extractor:
    filter_size: 256
    kernel_size: 3
    dropout: 0.2

  emtion_embedding_table:
    n_style_token: 10
    style_hidden: 256
    
  attn_head: 4
  attn_dim: 256


multi_speaker: False

max_seq_len: 1000

mist_wt: 0.1

n_mels: 80

num_speaker: 10
num_emotion: 5